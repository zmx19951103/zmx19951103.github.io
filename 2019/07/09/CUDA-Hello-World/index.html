<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="简介&amp;nbsp;&amp;nbsp;第一次尝试编写CUDA C程序，主要是和以后的希望从事的方向有关，想从事大规模机器学习和深度学习系统的开发，CUDA是不可避免的需要掌握的并行计算的框架. 正好实验室有gpu服务器，趁着暑假来学习一波CUDA编程.&amp;nbsp;&amp;nbsp;CUDA是NVIDIA推出的运算平台，是一种并行计算的架构，使用GPU来进行通用计算. 编译CUDA程序的流程&amp;nbsp;&amp;nbsp;">
<meta name="keywords" content="CUDA Programming">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA Hello World">
<meta property="og:url" content="http://yoursite.com/2019/07/09/CUDA-Hello-World/index.html">
<meta property="og:site_name" content="ZMX&#39;s Blog">
<meta property="og:description" content="简介&amp;nbsp;&amp;nbsp;第一次尝试编写CUDA C程序，主要是和以后的希望从事的方向有关，想从事大规模机器学习和深度学习系统的开发，CUDA是不可避免的需要掌握的并行计算的框架. 正好实验室有gpu服务器，趁着暑假来学习一波CUDA编程.&amp;nbsp;&amp;nbsp;CUDA是NVIDIA推出的运算平台，是一种并行计算的架构，使用GPU来进行通用计算. 编译CUDA程序的流程&amp;nbsp;&amp;nbsp;">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-07-23T09:14:58.913Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CUDA Hello World">
<meta name="twitter:description" content="简介&amp;nbsp;&amp;nbsp;第一次尝试编写CUDA C程序，主要是和以后的希望从事的方向有关，想从事大规模机器学习和深度学习系统的开发，CUDA是不可避免的需要掌握的并行计算的框架. 正好实验室有gpu服务器，趁着暑假来学习一波CUDA编程.&amp;nbsp;&amp;nbsp;CUDA是NVIDIA推出的运算平台，是一种并行计算的架构，使用GPU来进行通用计算. 编译CUDA程序的流程&amp;nbsp;&amp;nbsp;">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>CUDA Hello World</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss -->
    
    
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/tags/">tags</a></li>
         
          <li><a href="/links/">links</a></li>
         
          <li><a href="https://github.com/zmx19951103">Projects</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2019/07/10/GPU架构/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2019/07/06/逻辑回归交叉熵损失函数梯度推导/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://yoursite.com/2019/07/09/CUDA-Hello-World/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&text=CUDA Hello World"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&title=CUDA Hello World"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&is_video=false&description=CUDA Hello World"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=CUDA Hello World&body=Check out this article: http://yoursite.com/2019/07/09/CUDA-Hello-World/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&title=CUDA Hello World"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&title=CUDA Hello World"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&title=CUDA Hello World"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&title=CUDA Hello World"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&name=CUDA Hello World&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#编译CUDA程序的流程"><span class="toc-number">2.</span> <span class="toc-text">编译CUDA程序的流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA-Hello-World"><span class="toc-number">3.</span> <span class="toc-text">CUDA Hello World</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#global-限定符"><span class="toc-number">3.1.</span> <span class="toc-text">__global__ 限定符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lt-lt-lt-…-gt-gt-gt-语法"><span class="toc-number">3.2.</span> <span class="toc-text">&lt;&lt;&lt;…&gt;&gt;&gt; 语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cudaDeviceSynchronize"><span class="toc-number">3.3.</span> <span class="toc-text">cudaDeviceSynchronize</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Vector-Addition"><span class="toc-number">4.</span> <span class="toc-text">Vector Addition</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cudaMalloc和cudaFree"><span class="toc-number">4.1.</span> <span class="toc-text">cudaMalloc和cudaFree</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cudaMemcpy"><span class="toc-number">4.2.</span> <span class="toc-text">cudaMemcpy</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-number">5.</span> <span class="toc-text">参考</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        CUDA Hello World
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">ZMX's Blog</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2019-07-09T07:59:38.000Z" itemprop="datePublished">2019-07-09</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/CUDA-Programming/">CUDA Programming</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>&nbsp;&nbsp;第一次尝试编写CUDA C程序，主要是和以后的希望从事的方向有关，想从事大规模机器学习和深度学习系统的开发，CUDA是不可避免的需要掌握的并行计算的框架. 正好实验室有gpu服务器，趁着暑假来学习一波CUDA编程.<br>&nbsp;&nbsp;CUDA是NVIDIA推出的运算平台，是一种并行计算的架构，使用GPU来进行通用计算.</p>
<h2 id="编译CUDA程序的流程"><a href="#编译CUDA程序的流程" class="headerlink" title="编译CUDA程序的流程"></a>编译CUDA程序的流程</h2><p>&nbsp;&nbsp;编译一个CUDA程序和C程序一样，CUDA程序的编译器是nvcc, CUDA程序文件的后缀是.cu. 开设我们有一个CUDA程序文件，命名为hello.cu, 那么我们用nvcc将它编译为可执行文件的命令如下:</p>
<p><code>nvcc hello.cu -o hello</code></p>
<h2 id="CUDA-Hello-World"><a href="#CUDA-Hello-World" class="headerlink" title="CUDA Hello World"></a>CUDA Hello World</h2><p>&nbsp;&nbsp;学习任何程序设计语言的入门都是打印Hello World.CUDA程序也不例外， 下面我们以打印Hello World为例来解释CUDA程序的要素.</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"> <span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">hello</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"hello world from GPU\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">"hello world from CPU\n"</span>);</span><br><span class="line">  hello&lt;&lt;&lt;<span class="number">1</span>, <span class="number">10</span>&gt;&gt;&gt;();</span><br><span class="line">  cudaDeviceSynchronize();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们用与之功能相近的普通C程序作为对比<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">hello</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Hello World!\n"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    hello();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可以看到cuda程序相对于普通的c程序，有几点不同:</p>
<h3 id="global-限定符"><a href="#global-限定符" class="headerlink" title="__global__ 限定符"></a>__global__ 限定符</h3><p>&nbsp;&nbsp;在cuda程序中，cpu和gpu都用来做计算。我们把cpu叫做host，gpu叫做device. cpu和gpu拥有各自的存储空间。通常我们在cpu上顺序执行代码，在gpu上进行并行计算(Typically, we run serial workload on CPU and offload parallel computation to GPUs).<br>&nbsp;&nbsp;__global__限定符表示hello函数是在gpu上执行的，是device代码,而且<strong>被该修饰符修饰的函数可以被host上的代码调用</strong>(这一点很重要，之后我们会看到，有的限定符表示只能被device代码或者只能被host代码调用)，我们的例子里hello函数就是被host上的main函数调用的,这样的函数也叫”kernels”. <strong>A kernel function must have a void return type(核函数的返回类型必须是void)</strong></p>
<h3 id="lt-lt-lt-…-gt-gt-gt-语法"><a href="#lt-lt-lt-…-gt-gt-gt-语法" class="headerlink" title="&lt;&lt;&lt;…&gt;&gt;&gt; 语法"></a>&lt;&lt;&lt;…&gt;&gt;&gt; 语法</h3><p>&nbsp;&nbsp;当我们调用kernel的时候，它的执行的配置是通过&lt;&lt;&lt;…&gt;&gt;&gt;语法提供的，所谓的配置包括执行这个kernel用几个线程块，每个线程块开几个线程（这个涉及到gpu的结构）.比如上面的例子中，<code>hello&lt;&lt;&lt;1, 10&gt;&gt;&gt;();</code>. 在cuda中，这个叫做”kernel launch”(核启动). 具体参数之后的博客来说明.</p>
<h3 id="cudaDeviceSynchronize"><a href="#cudaDeviceSynchronize" class="headerlink" title="cudaDeviceSynchronize"></a>cudaDeviceSynchronize</h3><p>&nbsp;&nbsp; a kernel launch is asynchronous.因为kernel launch是异步执行的，当执行到device code的时候，在gpu上开启进程的时候，程序控制权就会回到cpu，不管gpu上的程序是否执行完毕。在我们的cuda程序中，如果没有cudaDeviceSynchronize函数，我们的程序就结束退出了，这样的话gpu端打印的hello world就不能打印到标准输出了. 而有了cudaDeviceSynchronize，cpu端的程序就会等device上的程序执行完后才退出，所以cudaDeviceSynchronize函数会阻塞直到device上的代码执行完毕.</p>
<h2 id="Vector-Addition"><a href="#Vector-Addition" class="headerlink" title="Vector Addition"></a>Vector Addition</h2><p>&nbsp;&nbsp;下面我们来看使用gpu进行向量相加运算的代码. 首先是使用cpu进行运算的代码：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 10000000</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">vector_add</span><span class="params">(<span class="keyword">float</span> *out, <span class="keyword">float</span> *a, <span class="keyword">float</span> *b, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">        out[i] = a[i] + b[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">float</span> *a, *b, *out; </span><br><span class="line"></span><br><span class="line">    <span class="comment">// Allocate memory</span></span><br><span class="line">    a   = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    b   = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    out = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Initialize array</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">        a[i] = <span class="number">1.0f</span>; b[i] = <span class="number">2.0f</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Main function</span></span><br><span class="line">    vector_add(out, a, b, N);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>下面我们把向量相加的部分放到gpu上进行并行运算:<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 100000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">vector_add</span><span class="params">(<span class="keyword">float</span> *out, <span class="keyword">float</span> *a, <span class="keyword">float</span> *b, <span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">        out[i] = a[i] + b[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">float</span> *a, *b, *out;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Allocate memory</span></span><br><span class="line">    a   = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    b   = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    out = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Initialize array</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123;</span><br><span class="line">        a[i] = <span class="number">1.0f</span>; b[i] = <span class="number">2.0f</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *d_a;</span><br><span class="line">    <span class="keyword">float</span> *d_b;</span><br><span class="line">    <span class="keyword">float</span> *d_out;</span><br><span class="line"></span><br><span class="line">    cudaMalloc((<span class="keyword">void</span>**)&amp;d_a, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    cudaMalloc((<span class="keyword">void</span>**)&amp;d_b, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    cudaMalloc((<span class="keyword">void</span>**)&amp;d_out, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    cudaMemcpy(d_a, a, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N, cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(d_b, b, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N, cudaMemcpyHostToDevice);</span><br><span class="line">    cudaMemcpy(d_out, out, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N, cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Main function</span></span><br><span class="line">    vector_add&lt;&lt;&lt;<span class="number">1</span>,<span class="number">10</span>&gt;&gt;&gt;(d_out, d_a, d_b, N);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//cudaMemcpy(a, d_a, sizeof(float) * N, cudaMemcpyDeviceToHost);</span></span><br><span class="line">    <span class="comment">//cudaMemcpy(b, d_b, sizeof(float) * N, cudaMemcpyDeviceToHost);</span></span><br><span class="line">    cudaMemcpy(out, d_out, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N, cudaMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt; N;i++)&#123;</span><br><span class="line">     <span class="built_in">printf</span>(<span class="string">"%f\n"</span>,out[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"end!!!!"</span>);</span><br><span class="line">    cudaFree(d_a);</span><br><span class="line">    cudaFree(d_b);</span><br><span class="line">    cudaFree(d_out);</span><br><span class="line">    <span class="built_in">free</span>(a);</span><br><span class="line">    <span class="built_in">free</span>(b);</span><br><span class="line">    <span class="built_in">free</span>(out);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>&nbsp;&nbsp;可能一开始，我们会向hello world程序一样，给vector_add函数添加__global__修饰符.然后在main函数中调用vector_add函数的地方添加&lt;&lt;&lt;…&gt;&gt;&gt;. 这样以后我们编译运行程序但是发现程序的执行结果和我们预想的不一样. 是什么原因导致的呢？<br>&nbsp;&nbsp;原因是cpu和gpu是各自拥有自己的存储空间,cpu无法直接获取gpu存储上的内容，gpu也无法直接获取到cpu存储上的内容. 在 cuda的术语里, cpu的存储叫做host memory, gpu的存储叫做device memory. 指向cpu内存的指针叫做host pointer, 指向gpu内存的指针叫做device pointer. 如果要让gpu能够获取到数据，那么数据必须在device memory上，cuda提供了分配device memory和在host和device之间进行数据迁移的api,cuda 程序的一个常见的流程如下:</p>
<ul>
<li>分配host memory并初始化host上的数据</li>
<li>分配device memory(cudaMalloc)</li>
<li>将kernel函数要用的数据从host迁移到device上(cudaMemcpy)</li>
<li>执行kernel函数</li>
<li>将kernel函数的输出从device迁移到host上(cudaMemcpy)</li>
</ul>
<p>vec_add在gpu上运行，而out,a,b这三个向量，传入的是cpu上的地址空间，因此结果和我们预期的不一样. 这里还有个疑问，那为啥程序不报错呢，传入的是cpu上的存储地址.核函数内部居然不报错？</p>
<p>这个程序相比于前面的hello world程序有很多新的函数需要解释：</p>
<h3 id="cudaMalloc和cudaFree"><a href="#cudaMalloc和cudaFree" class="headerlink" title="cudaMalloc和cudaFree"></a>cudaMalloc和cudaFree</h3><p>&nbsp;&nbsp;这两个函数类似于c语言中的malloc和free函数，只不过这两个函数是在device memory上分配空间, 他们的函数原型如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">cudaMalloc(<span class="keyword">void</span> **devPtr, <span class="keyword">size_t</span> count);</span><br><span class="line">cudaFree(<span class="keyword">void</span> *devPtr);</span><br></pre></td></tr></table></figure></p>
<p>cudaMalloc函数在device memory上分配size为count的空间，然后让devPtr指向分配的空间. 而 cudaFree将devPtr指向的空间给free了.</p>
<h3 id="cudaMemcpy"><a href="#cudaMemcpy" class="headerlink" title="cudaMemcpy"></a>cudaMemcpy</h3><p>&nbsp;&nbsp;cudaMemcpy函数用来在host和device之间传递数据，和c中的memcpy函数很像. 语法如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">cudaMemcpy(<span class="keyword">void</span> *dst, <span class="keyword">void</span> *src, <span class="keyword">size_t</span> count, cudaMemcpyKind kind)</span><br></pre></td></tr></table></figure></p>
<p>这个函数将size为count的存储从src复制到dst,kind指示复制的方向，最常用的值是cudaMemcpyHostToDevice 以及 cudaMemcpyDeviceToHost，分别表示从host复制到device以及从device复制到host.</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://cuda-tutorial.readthedocs.io/en/latest/tutorials/tutorial01/" target="_blank" rel="noopener">Tutorial 01:Say Hello to CUDA</a><br><a href="https://stackoverflow.com/questions/19193468/why-do-we-need-cudadevicesynchronize-in-kernels-with-device-printf" target="_blank" rel="noopener">why do we need cudaDeviceSynchronize</a><br><a href="https://stackoverflow.com/questions/25332476/cudadevicesynchronize-and-performing-sequential-work?noredirect=1" target="_blank" rel="noopener">cudaDeviceSynchronize and performing sequential work</a></p>

  </div>
</article>

    <div class="blog-post-comments">
        <div id="disqus_thread">
            <noscript>Please enable JavaScript to view the comments.</noscript>
        </div>
    </div>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/tags/">tags</a></li>
         
          <li><a href="/links/">links</a></li>
         
          <li><a href="https://github.com/zmx19951103">Projects</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#简介"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#编译CUDA程序的流程"><span class="toc-number">2.</span> <span class="toc-text">编译CUDA程序的流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CUDA-Hello-World"><span class="toc-number">3.</span> <span class="toc-text">CUDA Hello World</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#global-限定符"><span class="toc-number">3.1.</span> <span class="toc-text">__global__ 限定符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#lt-lt-lt-…-gt-gt-gt-语法"><span class="toc-number">3.2.</span> <span class="toc-text">&lt;&lt;&lt;…&gt;&gt;&gt; 语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cudaDeviceSynchronize"><span class="toc-number">3.3.</span> <span class="toc-text">cudaDeviceSynchronize</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Vector-Addition"><span class="toc-number">4.</span> <span class="toc-text">Vector Addition</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#cudaMalloc和cudaFree"><span class="toc-number">4.1.</span> <span class="toc-text">cudaMalloc和cudaFree</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cudaMemcpy"><span class="toc-number">4.2.</span> <span class="toc-text">cudaMemcpy</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-number">5.</span> <span class="toc-text">参考</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" href="http://www.facebook.com/sharer.php?u=http://yoursite.com/2019/07/09/CUDA-Hello-World/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://twitter.com/share?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&text=CUDA Hello World"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.linkedin.com/shareArticle?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&title=CUDA Hello World"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://pinterest.com/pin/create/bookmarklet/?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&is_video=false&description=CUDA Hello World"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=CUDA Hello World&body=Check out this article: http://yoursite.com/2019/07/09/CUDA-Hello-World/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="https://getpocket.com/save?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&title=CUDA Hello World"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://reddit.com/submit?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&title=CUDA Hello World"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.stumbleupon.com/submit?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&title=CUDA Hello World"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://digg.com/submit?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&title=CUDA Hello World"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="http://www.tumblr.com/share/link?url=http://yoursite.com/2019/07/09/CUDA-Hello-World/&name=CUDA Hello World&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy; 2019 Zmx
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/tags/">tags</a></li>
         
          <li><a href="/links/">links</a></li>
         
          <li><a href="https://github.com/zmx19951103">Projects</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

    <!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Disqus Comments -->

    <script type="text/javascript">
        var disqus_shortname = 'zmxdream';

        (function(){
            var dsq = document.createElement('script');
            dsq.type = 'text/javascript';
            dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        }());
    </script>


</body>
</html>
